```{r}
source("_utils.R")
```

```{r}
#| cache: true
#| cache-extra: !expr rlang::hash(params)
#| cache-file-1: !expr rlang::hash_file("_baseline_query_data.R")
source("_baseline_query_data.R")
```

# Changed Values by Year

```{r changed_values_processing}
# Build card_data with dataset label
common_cols <- intersect(names(comp_chars), names(baseline_assessment_data))

card_data <- bind_rows(
  comp = comp_chars %>% select(all_of(common_cols)),
  baseline = baseline_assessment_data %>% select(all_of(common_cols)),
  .id = "dataset" # "comp" or "baseline"
) %>%
  group_by(meta_pin, meta_card_num) %>%
  # keep only PIN-card combos appearing in both datasets
  filter(n() > 1) %>%
  ungroup() %>%
  arrange(meta_pin, meta_card_num) %>%
  as.data.table()

setnames(card_data, "meta_year", "year")

# Keys and comparison columns
key_cols <- c("meta_pin", "meta_card_num")
cols <- setdiff(names(card_data), c(key_cols, "dataset"))

# tolerance list:
# Many of our features should be exact matches but are not. For example,
# our distance to features have some minor variation due to geocoding variance.
# Because of this, all distance features have a buffer of 5 feet.
# There are also features which should not match, but we want to make sure that
# they stay relatively stable. For example, the percentage of college educated
# individuals should not change by more than 10% year over year.
base_tol <- c(
  acs5_median_age_total = 10,
  acs5_median_household_renter_occupied_gross_rent = 500,
  acs5_median_household_total_occupied_year_built = 10,
  acs5_median_income_household_past_year = 20000,
  acs5_median_income_per_capita_past_year = 15000,
  loc_latitude = 0.0001,
  loc_longitude = 0.0001,
  other_tax_bill_rate = 5,
  prox_num_pin_in_half_mile = 10,
  prox_airport_dnl_total = 1,
  prox_num_foreclosure_per_1000_pin_past_5_years = 5,
  prox_num_bus_stop_in_half_mile = 2,
  time_sale_day = 31,
  time_sale_day_of_week = 7,
  time_sale_year = 1,
  year = 1,
  prox_nearest_park_dist_ft = 100,
  prox_nearest_vacant_land_dist_ft = 100,
  meta_sale_count_past_n_years = 1
)

make_tol <- function(cols) {
  tibble(col = cols) %>%
    mutate(val = case_when(
      col %in% names(base_tol) ~ base_tol[match(col, names(base_tol))],
      # Create standard ditstance and acs tolerances
      str_detect(col, "dist_ft$") ~ 5,
      str_detect(col, "^acs5_percent_") ~ 0.1,
      TRUE ~ NA_real_
    )) %>%
    {
      setNames(.$val, .$col)
    }
}

tol <- make_tol(cols)
tol_defined <- !is.na(tol) # TRUE only where a tolerance exists

# Group-wise checks: numeric path only if tolerance is defined
# Otherwise use exact matching
group_matches <- card_data[
  ,
  {
    res <- mapply(
      function(value, name) {
        t <- tol[[name]]

        # Both NA returns match
        if (all(is.na(value))) {
          return(TRUE)
        }

        # Any single NA present returns no match
        if (any(is.na(value))) {
          return(FALSE)
        }

        # Numeric path if tolerance is defined
        if (isTRUE(tol_defined[[name]])) {
          numeric_value <- suppressWarnings(as.numeric(value))
          (max(numeric_value) - min(numeric_value)) <= t
        } else {
          uniqueN(value) <= 1 # exact match path
        }
      },
      .SD, names(.SD),
      SIMPLIFY = FALSE
    )

    as.list(res)
  },
  by = key_cols,
  .SDcols = cols
]

card_matches_long <- melt(
  as.data.table(group_matches),
  id.vars = key_cols,
  variable.name = "column",
  value.name = "is_match"
)

card_matches_long <- card_matches_long %>%
  mutate(tolerance = unname(tol[as.character(column)]))

# Summarize non-matching counts and include tolerance
count_not_matching <- card_matches_long %>%
  filter(!is_match) %>%
  group_by(Column = column) %>%
  summarise(Count = n(), .groups = "drop") %>%
  mutate(Tolerance = unname(tol[as.character(Column)])) %>%
  arrange(desc(Count))
```

::: {.panel-tabset}

## Count of Unmatched Values

```{r unmatched_values}
DT::datatable(
  count_not_matching,
  options = list(
    scrollY = "300px",
    scrollX = TRUE,
    paging = TRUE,
    pageLength = 100,
    searching = TRUE
  ),
  rownames = FALSE
)
```


## Count of Unique Changes

Because many PINs will have the same expected change (for example ACS Household
Income changing from 100,000 to 130,000), we group these into unique changes.

```{r unique_counts}
unmatched_values_long <-
  as.data.table(card_data)[
    , melt(
      .SD,
      id.vars = c(key_cols, "dataset"),
      measure.vars = cols,
      variable.name = "column",
      value.name = "value"
    )
  ][
    # inner join to keep only failed combinations
    card_matches_long[is_match == FALSE, .(meta_pin, meta_card_num, column)][
      , column := as.character(column)
    ],
    on = .(meta_pin, meta_card_num, column),
    nomatch = 0
  ][
    order(column, meta_pin, meta_card_num, dataset)
  ]

changes_summary <- unmatched_values_long %>%
  as_tibble() %>%
  # Rename comp and baseline to new and old for readability
  group_by(column, meta_pin, meta_card_num) %>%
  summarise(
    old_value = value[dataset == "comp"][1],
    new_value = value[dataset == "baseline"][1],
    .groups = "drop"
  ) %>%
  # Count specific old -> new change occurrences
  group_by(column, old_value, new_value) %>%
  summarise(
    n = n(),
    .groups = "drop"
  ) %>%
  # Number of unique changes for that column
  group_by(column) %>%
  mutate(
    N_unique_changes = n_distinct(paste0(old_value, "->", new_value))
  ) %>%
  ungroup()

changes_summary %>%
  arrange(desc(N_unique_changes), desc(n)) %>%
  select(column, N_unique_changes) %>%
  distinct(column, .keep_all = TRUE) %>%
  DT::datatable(
    options = list(
      scrollY = "300px",
      scrollX = TRUE,
      paging = TRUE,
      pageLength = 100,
      searching = TRUE
    ),
    rownames = FALSE
  )
```

:::
```{r card_level_changes}
make_card_comp_chart <- function(col_name) {
  # Filter to the column of interest
  chart_data_long <- unmatched_values_long[column == col_name]

  # Tag rows as old/new based on dataset:
  chart_data_long[, tag := fcase(
    dataset == "comp", "old",
    dataset == "baseline", "new"
  )]

  # Pivot to wide: one row per PIN/Card with old/new values
  chart_data_wide <- dcast(
    chart_data_long,
    meta_pin + meta_card_num ~ tag,
    value.var = "value"
  )

  # Rename columns to <col_name>_new (baseline) and <col_name>_old (comp)
  setnames(
    chart_data_wide,
    old = c("new", "old"),
    new = c(paste0(col_name, "_new"), paste0(col_name, "_old"))
  )

  # Names for  old/new cols
  old_nm <- paste0(col_name, "_old")
  new_nm <- paste0(col_name, "_new")

  # Count how many times each old/new pair occurs
  pair_counts <- chart_data_wide[
    ,
    .(n = .N),
    by = c(old_nm, new_nm)
  ]

  # Join counts back to the detailed table
  chart_data_wide <- merge(
    chart_data_wide,
    pair_counts,
    by = c(old_nm, new_nm),
    all.x = TRUE
  )

  order <- c("meta_pin", "meta_card_num", old_nm, new_nm, "n")
  present <- intersect(order, names(chart_data_wide))
  data.table::setcolorder(chart_data_wide, present)

  # Cap at 1,000 rows for readability with sample
  if (nrow(chart_data_wide) > 1000L) {
    chart_data_wide <- chart_data_wide[sample(.N, 1000L)]
  }

  chart_data_wide[]
}


unmatched_tables <- unique(unmatched_values_long$column) %>%
  lapply(make_card_comp_chart) %>%
  (\(x) setNames(x, unique(unmatched_values_long$column)))() %>%
  (\(x) x[!vapply(x, is.null, logical(1))])()

unmatched_charts <- list()

vars <- sort(names(unmatched_tables))

for (var in vars) {
  tbl <- unmatched_tables[[var]]

  unmatched_charts[[var]] <- knitr::kable(
    tbl,
    format = "html",
    caption = sprintf("Unmatched values for %s", var),
    row.names = FALSE,
    align = rep("l", ncol(tbl))
  ) %>%
    kableExtra::kable_styling(
      bootstrap_options = c("striped", "hover", "condensed", "responsive"),
      full_width = FALSE
    ) %>%
    kableExtra::scroll_box(
      height = "400px",
      width = "100%",
      box_css = "border: 1px solid #ddd; padding: 5px;"
    )
}
```

## Distinct Unmatched Values by Pin-Card Combo

For values where n is > 1, the PIN selected is arbitrary and solely used for
reference.

::: {.panel-tabset}

```{r, results = 'asis'}
for (i in seq_along(unmatched_charts)) {
  cat("### ", names(unmatched_charts)[i], "\n\n")
  print(unmatched_charts[[i]])
  cat("\n\n")
}
```
:::

## Count of Empty Strings (Should be Empty)

```{r empty_string_counts}
card_data %>%
  summarize(across(everything(), ~ sum(. == "", na.rm = TRUE))) %>%
  pivot_longer(
    cols = everything(),
    names_to = "column",
    values_to = "empty_string_count"
  ) %>%
  filter(empty_string_count > 0) %>%
  arrange(desc(empty_string_count)) %>%
  DT::datatable(
    options = list(
      scrollY = "300px",
      scrollX = TRUE,
      paging = TRUE,
      pageLength = 100,
      searching = TRUE
    ),
    rownames = FALSE
  )
```

```{r data_changes_cleanup}
#| output: false

rm(
  card_data, common_cols,
  group_matches, card_matches_long, count_not_matching,
  unmatched_values_long, unmatched_tables, unmatched_charts
)
gc()
```
