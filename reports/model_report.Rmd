---
title: "Model Summary"
date: "`r format(Sys.time(), '%d %B, %Y @ %r')`"
output: html_document
params:
  filter: "TRUE"
  triad: "City"
---

```{r setup, include=FALSE}
# Load R libraries
library(arrow)
library(assessr)
library(ccao)
library(dplyr)
library(DT)
library(forcats)
library(ggplot2)
library(here)
library(lightgbm)
library(lubridate)
library(purrr)
library(recipes)
library(scales)
library(sf)
library(stringr)
library(tidyr)
library(tune)
library(yardstick)
source(here("R", "model_funs.R"))

# Hide code output and make plots take 100% of page width
knitr::opts_chunk$set(echo = FALSE, out.width = '100%')

# Filter to specific triad. Set with system variable else param defined in yaml
report_filter <- Sys.getenv("R_REPORT_FILTER", unset = NA)
report_filter <- as.logical(ifelse(
  !is.na(report_filter),
  report_filter,
  params$filter
))

# Triad to use for report if filtered. Set with system variable else param
# defined in yaml
report_triad <- Sys.getenv("R_REPORT_TRIAD", unset = NA)
report_triad <- ifelse(!is.na(report_triad), report_triad, params$triad)
```

```{r model_timing, results='asis'}
# Print total training time if timings file exists. This looks for the 
# lightgbm CV section timing, which is the HUGE majority of training time
model_timings_path <- here("output", "params", "model_timings.rds")
if (file.exists(model_timings_path)) {
  readRDS(model_timings_path) %>%
    filter(model == "lightgbm") %>%
    pull(elapsed) %>%
    round(0) %>%
    seconds_to_period() %>%
    paste("Model took", ., "to train") %>%
    cat()
}
```

```{r model_summary, message=FALSE, warning=FALSE}
# Load test set results from model.R and add town/triad information
test_res <- read_parquet(here("output", "data", "testdata.parquet")) %>%
  mutate(
    town_name = town_convert(meta_town_code),
    triad = factor(
      town_get_triad(meta_town_code, name = TRUE),
      levels = c("North", "City", "South")
    )
  )
  
# Get aggregate model performance by type (LightGBM and linear)
test_res %>%
  pivot_longer(enet:lgbm, names_to = "Model Type") %>%
  group_by(`Model Type`) %>%
  summarise(
    `R<sup>2</sup>` = rsq_trad_vec(meta_sale_price, value),
    RMSE = scales::dollar(rmse_vec(meta_sale_price, value), accuracy = 1),
    MAE = scales::dollar(mae_vec(meta_sale_price, value), accuracy = 1),
    MAPE = scales::percent(mape_vec(meta_sale_price, value) / 100)
  ) %>%
  mutate(`Model Type` = recode(`Model Type`, enet = "Linear", lgbm = "LightGBM")) %>%
  knitr::kable(format = "markdown", digits = 2)
```

<br>

## Model Breakdown by Township

```{r model_summary_by_town, message=FALSE, warning=FALSE}
# Filter to specific triad based on report parameter
if (report_filter) {
test_res <- test_res %>%
  filter(triad == report_triad)
}

# Summarize test set results by township. Values prefixed with final_ are
# filtered according to CCAO SOPs on ratio studies (top and bottom 5% of ratios
# are excluded)
test_summary <- test_res %>%
  group_by(town_name) %>%
  summarize(
    med_sp = median(meta_sale_price),
    count = n(),
    prop = n() / nrow(.),
    across(enet:lgbm, ~ cod(.x / meta_sale_price), .names = "{.col}_cod"),
    final_cod = ccao_cod(lgbm / meta_sale_price, suppress = TRUE)$COD,
    final_prd = ccao_prd(lgbm, meta_sale_price, suppress = TRUE)$PRD,
    final_prb = ccao_prb(lgbm, meta_sale_price, suppress = TRUE)$PRB,
    final_ratio = median(lgbm / meta_sale_price, na.rm = TRUE)
  ) %>%
  mutate(
    final_cod_met = cod_met(round(final_cod, 2)),
    final_prd_met = prd_met(round(final_prd, 2)),
    final_prb_met = prb_met(round(final_prb, 2)),
    final_ratio_met = between(final_ratio, 0.95, 1.05)
  ) %>%
  arrange(final_cod)

# Create a container with custom column headers for model summary table. This
# is purely aesthetic
headers <- htmltools::withTags(table(
  class = "display", 
  thead(
    tr(
      th(rowspan = 2, "Township"),
      th(rowspan = 2, "Median Sale Price"),
      th(rowspan = 2, "Number of Sales"),
      th(rowspan = 2, "Proportion of Total Sales"),
      th(rowspan = 2, "Linear (Baseline)"),
      th(rowspan = 2, "Raw Model"),
      th(colspan = 4, "Final Model Stats")
    ),
    tr(
      th("COD"), th("PRD"), th("PRB"), th("Med. Ratio")
    )
  )
))

# Create an interactive table of the test set results by township
test_summary %>%
  datatable(
    rownames = FALSE,
    filter = "none",
    selection = "none",
    container = headers,
    escape = FALSE,
    options = list(
      autoWidth = TRUE,
      paging = FALSE,
      searching = FALSE,
      info = FALSE,
      columnDefs = list(list(targets = 10:13, visible = FALSE))
    )
  ) %>%
  formatCurrency(2, digits = 0) %>%
  formatRound(3, digits = 0) %>%
  formatPercentage(4, digits = 1) %>%
  formatRound(c(5:10)) %>%
  formatStyle(  
    c("final_cod", "final_prd", "final_prb", "final_ratio"),
    c("final_cod_met", "final_prd_met", "final_prb_met", "final_ratio_met"),
    backgroundColor = styleEqual(
      c(0, 1),
      c("transparent", "#81ca9c")
    )
  )
```

<br>

## Map of COD by Township by Model Type

```{r model_map}
# Vector of model name order (in the order run in model.R)
model_order <- c("enet", "lgbm", "final")

# Generate township level map of COD
test_summary %>%
  rename(enet = enet_cod, lgbm = lgbm_cod, final = final_cod) %>%
  pivot_longer(c(enet, lgbm, final)) %>%
  left_join(ccao::town_shp, by = c("town_name" = "township_name")) %>%
  st_set_geometry("geometry") %>%
  mutate(name = factor(name, levels = model_order)) %>%
ggplot() +
  geom_sf(aes(fill = value, geometry = geometry)) +
  scale_fill_distiller(name = "COD", palette = "Spectral") +
  facet_wrap(vars(name)) +
  theme_void() +
  theme(
    strip.text = element_text(size = 14, margin = margin(b = 3))
  )
```

## Variables Used in Final Model

```{r model_vars}
# Load the saved model from file so we can extract the modeling variables from
# its recipe
lgbm_recipe <- readRDS(here("output", "models", "lgbm_recipe.rds"))

# Get the predictors used in the model and rename them to their human-readable
# format
test_vars <- bake(lgbm_recipe, test_res, all_predictors()) %>%
  vars_rename(names_from = "standard", names_to = "pretty") %>%
  rename(
    "Age" = char_age_poly_1, "Age ^ 2" = char_age_poly_2,
    "Building Sqft." = char_bldg_sf_poly_1, "Building Sqft. ^ 2" = char_bldg_sf_poly_2,
    "Land Sqft." = char_hd_sf_poly_1, "Land Sqft. ^ 2" = char_hd_sf_poly_2
  )

# Create a table of variable names and attributes
tibble(
  "Variable Name" = names(test_vars),
  "Variable Type" = map_chr(test_vars, class),
  "Number of Categories" = na_if(map_int(test_vars, ~ length(levels(.x))), 0),
  "Median Value" = map_dbl(test_vars, ~ ifelse(is.factor(.x), NA, median(.x)))
) %>%
  knitr::kable(digits = 3)

```

<br>

## Ratio Distribution by Township by Sale Price Decile

```{r ratio_decile, warning=FALSE, message=FALSE, results='hide'}
# Split test set results into sale price decile, then calculate distribution of 
# ratios for each decile by township
decile_data <- test_res %>%
  mutate(
    decile = ntile(meta_sale_price, 10),
    across(enet:lgbm, ~ .x / meta_sale_price)
  ) %>%
  group_by(decile) %>%
  mutate(decile_label = paste(
    dollar(min(meta_sale_price), 1, scale = 1/1000, suffix = "K"),
    dollar(max(meta_sale_price), 1, scale = 1/1000, suffix = "K"),
    sep = " - ")
  ) %>%
  ungroup() %>%
  mutate(decile_label = fct_rev(fct_reorder(factor(decile_label), decile))) %>%
  pivot_longer(enet:lgbm, names_to = "model", values_to = "ratio") %>%
  mutate(model = factor(model, levels = model_order))

# Function to create decile plot based on a grouping variable
decile_plot <- function(data, col_var) {
  
  data %>%
    group_by({{col_var}}, decile_label) %>%
    mutate(count = n()) %>%
  ggplot() +
    geom_boxplot(aes(x = ratio), outlier.alpha = 0.05) +
    geom_text(
      aes(x = 3, y = 0.25, label = count),
      size = 3,
      hjust = 1,
      check_overlap = TRUE
    ) +
    facet_grid(
      rows = vars(decile_label),
      cols = vars({{col_var}}),
      switch = "y"
    ) +
    xlim(0, 3) +
    labs(x = "Sale Ratio", y = "") +
    theme_minimal() +
    theme(
      axis.title.x = element_text(margin = margin(t = 10), size = 10),
      axis.text.y = element_blank(),
      panel.grid.major.y = element_blank(),
      panel.grid.minor.y = element_blank(),
      strip.text = element_text(size = 12),
      strip.text.y.left = element_text(angle = 0, hjust = 1),
      strip.text.x = element_text(margin = margin(b = 10)),
      panel.grid.minor = element_blank()
    )
}

# Split into a separate decile plot for every 4 townships, otherwise all
# townships would be in a single plot
chunk <- function(x, n) split(x, sort(rank(x) %% n))
towns <- sort(unique(decile_data$town_name))
towns <- chunk(towns, ceiling(length(towns) / 4))

lapply(towns, function(chunk) decile_plot(
  decile_data %>% filter(town_name %in% chunk),
  town_name
))

```

<br>

## Ratio Distribution by Model Type by Sale Price Decile

```{r ratio_model, warning=FALSE}
# Create a distribution of ratios plot for each model type (enet and lightgbm)
decile_plot(decile_data, model)
```

<br>

# Outlier Analysis

---

## Overall Ratio Distribution (Model Pred. / Sale Price)

```{r outlier_dist, warning=FALSE, message=FALSE}
# Get the overall distribution of ratios for the lightgbm model. Flag ratios
# that would be trimmed according to CCAO SOPs using the is_outlier() function
outlier_dist <- test_res %>%
  group_by(town_name) %>%
  mutate(
    outlier = is_outlier(lgbm / meta_sale_price, method = "quantile"),
    trimmed = "Trimmed"
  ) %>%
  filter(!outlier) %>%
  bind_rows(test_res %>% mutate(trimmed = "Not Trimmed")) %>%
  mutate(ratio = lgbm / meta_sale_price) 

# Find 1st and 99th percentile for trimmed and untrimmed ratios
quantiles <- outlier_dist %>%
  group_by(trimmed) %>%
  summarize(q01 = quantile(ratio, 0.01), q99 = quantile(ratio, 0.99))

# Plot histogram of ratios, where the colored areas represent the 1st and 99th
# percentile for each distribution
ggplot(outlier_dist) +
  geom_histogram(aes(x = ratio), binwidth = 0.05) +
  geom_rect(
    data = quantiles,
    aes(xmin = -Inf, xmax = q01, ymin = -Inf, ymax = Inf, fill = trimmed),
    alpha = 0.3
  ) +
  geom_rect(
    data = quantiles,
    aes(xmin = q99, xmax = Inf, ymin = -Inf, ymax = Inf, fill = trimmed),
    alpha = 0.3
  ) +
  scale_x_continuous(breaks = breaks_extended(10), limits = c(0, 4)) +
  guides(fill = FALSE) +
  labs(
    x = "Sale Ratio",
    y = "Number of Properties",
    caption = "*Colored regions represent < 1st and > 99th percentile"
  ) +
  facet_wrap(vars(trimmed), ncol = 1) +
  theme_minimal() +
  theme(
    strip.text = element_text(size = 12),
    axis.title.x = element_text(margin = margin(t = 6), size = 10),
    axis.title.y = element_text(margin = margin(r = 10), size = 10),
    panel.grid.minor = element_blank()
  ) +
  theme(
    strip.text = element_text(size = 12)
  )

```

<br>

## Spatial Distribution of Outliers

```{r outlier_map, message=FALSE}
# Create a township level map showing the location of individual outliers within
# the 1st and 99th percentile from the histogram above
outlier_dist %>%
  left_join(quantiles, by = "trimmed") %>%
  filter(ratio < q01 | ratio > q99) %>%
  mutate(above_1 = ifelse(ratio > 1, "Above 1", "Below 1")) %>%
  ungroup() %>%
  st_as_sf(coords = c("geo_longitude", "geo_latitude"), crs = 4326) %>%
ggplot() +
  geom_sf(data = town_shp %>% filter(township_name %in% test_res$town_name)) +
  geom_sf(aes(geometry = geometry, color = trimmed, shape = above_1)) +
  scale_shape_manual(name = "Ratio is:", values = c("Above 1" = 0, "Below 1" = 16)) +
  facet_wrap(vars(trimmed), nrow = 1) +
  guides(color = FALSE) +
  theme_void() +
  theme(
    strip.text = element_text(size = 12)
  )

```

<br>

## Outlier Table

Table shows only observations with ratios less than the 0.1 percentile and greater than the 99.9 percentile.

```{r outlier_table}
# Create a table of outliers from the 0.01 and 99.9 percentiles of both trimmed
# and untrimmed values. These are the largest outliers by magnitude of error
outlier_dist %>%
  group_by(trimmed) %>%
  mutate(q01 = quantile(ratio, 0.001), q99 = quantile(ratio, 0.999)) %>%
  ungroup() %>%
  filter(ratio < q01 | ratio > q99) %>%
  mutate(
    meta_pin = pin_format_pretty(meta_pin),
    econ_tax_rate = econ_tax_rate / 100,
    Address = paste(geo_property_address, geo_property_zip, sep = ", "),
    ratio = round(ratio, 2)
  ) %>%
  select(
    Trimmed = trimmed, Township = town_name, PIN = meta_pin, Address, 
    `Model Prediction` = lgbm, `Sale Price` = meta_sale_price, Ratio = ratio, meta_class,
    any_of(vars_dict %>% filter(var_is_predictor) %>% pull(var_name_standard)),
    -meta_town_code
  ) %>%
  vars_recode(type = "short", as_factor = FALSE) %>%
  vars_rename(names_from = "standard", names_to = "pretty") %>%
  datatable(
    rownames = FALSE,
    selection = "none",
    options = list(
      scrollX = TRUE,
      autoWidth = TRUE,
      searchHighlight = TRUE,
      paging = TRUE,
      columnDefs = list(list(targets = c(2, 3), width = "100px"))
    )
  ) %>%
  formatStyle(
    "Trimmed",
    target = "row",
    backgroundColor = styleEqual(
      c("Trimmed", "Not Trimmed"),
      c("#ace2e3", "#f2b1ac")
    )
  ) %>%
  formatCurrency(
    c("Sale Price", "Model Prediction", "Tract Median Income"),
    digits = 0
  ) %>%
  formatPercentage(
    c("Tax Rate"), digits = 2
  )
```

<br>

# Model Analysis

---

## Feature Importance

```{r feat_imp, warning=FALSE}
# If model file exists, calculate feature importance using lightgbm's built in
# functionality, which measures gain
lgbm_model_path <- here("output", "models", "lgbm_model.zip")
if (file.exists(lgbm_model_path)) {
  lgbm_final_full_fit <- model_load(lgbm_model_path)

  # Get feature importance (gain) for lightgbm model (TAKES A LONG TIME TO RUN)
  lgbm_feat_imp <- lgb.importance(lgbm_final_full_fit$fit)
 
  # Create a horizontal bar plot showing the top N features' gain and cover 
  tibble(lgbm_feat_imp) %>%
    arrange(desc(Gain)) %>%
    dplyr::slice(1:30) %>%
    mutate(Feature = fct_reorder(Feature, Gain)) %>%
    pivot_longer(cols = c(Gain, Cover)) %>%
    mutate(name = factor(name, levels = c("Gain", "Cover"))) %>%
  ggplot() +
    geom_col(aes(y = Feature, x = value)) +
    facet_wrap(vars(name), nrow = 1, scales = "free_x") +
    labs(x = "", y = "") +
    theme_minimal() +
    theme(
      plot.margin = margin(0, 0, 0, 0),
      panel.grid.major.y = element_blank()
    )
}
```

## Hyperparameter Tuning

```{r param_plots, warning=FALSE, message=FALSE}
# Load hyperparameters data from file if it exists
lgbm_params_path <- here("output", "params", "lgbm_params.rds")
if (file.exists(lgbm_params_path)) {
  lgbm_params <- readRDS(lgbm_params_path)
  lgbm_final_params <- lgbm_params %>%
    mutate(iterations = max(.iter)) %>%
    select_best(metric = "rmse") %>%
    model_cap_num_leaves() %>%
    mutate(.config = str_remove(.config, "Iter"))
}

# If parameters exist, generate an autoplot of the CV results
if (exists("lgbm_params")) {
  autoplot(lgbm_params, metric = "rmse", type = "marginals") +
    geom_smooth(se = F) +
    theme_minimal()
}
```

## Final Hyperparameters

```{r param_final}
# Custom headers for parameter results table, purely aesthetic
param_headers <- htmltools::withTags(table(
  class = "display", 
  thead(
    tr(
      th(rowspan = 2, "Total Iterations"),
      th(rowspan = 2, "Best Iteration"),
      th(colspan = 7, "Parameters"),
    ),
    tr(
      th("mtry"), th("min_n"), th("tree_depth"),
      th("learn_rate"), th("loss_reduction"), th("num_leaves")
    )
  )
))

# Table of all final model hyperparameters that were used
lgbm_final_params %>%
  select(-any_of(c(
    "n", "std_err", ".iter", ".metric", ".estimator",
    ".best", ".bound", "rmse", "rsq", "cod", "prd", "prb"
  ))) %>%
  relocate(c(iterations, .config), .before = NULL) %>%
  datatable(
    rownames = FALSE,
    filter = "none",
    selection = "none",
    container = param_headers,
    escape = FALSE,
    options = list(
      scrollX = TRUE,
      paging = FALSE,
      searching = FALSE,
      info = FALSE
    )
  ) %>%
  formatRound(c(6:7), digits = 4)
```
