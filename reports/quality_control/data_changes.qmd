

```{r}
#| cache: true
#| cache-extra: !expr rlang::hash(params)
#| cache-file-1: !expr rlang::hash_file("_baseline_query_data.R")
#| cache-file-2: !expr rlang::hash_file("_utils.R")
```


```{r _data_changes_setup_script}
source("_baseline_query_data.R")
```

# Changed Values by Year

```{r changed_values_processing}
# Get only the common columns between runs
common_cols <- intersect(names(comp_chars), names(baseline_chars))

# Subset both datasets to those common columns
comp_common <- comp_chars[, common_cols, drop = FALSE]
baseline_common <- baseline_chars[, common_cols, drop = FALSE]

# row-bind
card_data <- rbind(comp_common, baseline_common)

dt <- as.data.table(card_data)[order(meta_pin, meta_card_num)]
setnames(dt, "meta_year", "year")

key_cols <- c("meta_pin", "meta_card_num")
cols <- setdiff(names(dt), key_cols)

# tolerance list:
# Many of our features should be exact matches but are not. For example,
# our distance to features have some minor variation due to geocoding variance.
# Because of this, all distance features have a buffer of 5 feet.
# There are also features which should not match, but we want to make sure that
# they stay relatively stable. For example, the percentage of college educated
# individuals should not change by more than 5% year over year.

# Create tolerance list
base_tol <- c(
  acs5_median_age_total = 5,
  acs5_median_household_renter_occupied_gross_rent = 400,
  acs5_median_household_total_occupied_year_built = 5,
  acs5_median_income_household_past_year = 10000,
  acs5_median_income_per_capita_past_year = 7500,
  ccao_n_years_exe_homeowner = 1,
  loc_latitude = 0.0001,
  loc_longitude = 0.0001,
  other_tax_bill_rate = 0.5,
  prox_airport_dnl_total = 1,
  prox_num_foreclosure_per_1000_pin_past_5_years = 5,
  time_sale_day = 31,
  time_sale_day_of_week = 7,
  time_sale_year = 1,
  year = 1
)

make_tol <- function(cols) {
  tibble(col = cols) %>%
    mutate(val = case_when(
      col %in% names(base_tol) ~ base_tol[match(col, names(base_tol))],
      str_detect(col, "dist_ft$") ~ 5,
      str_detect(col, "^acs5_percent_") ~ 0.1,
      TRUE ~ NA_real_
    )) %>%
    {
      setNames(.$val, .$col)
    }
}

tol <- make_tol(cols)

tol_defined <- !is.na(tol) # TRUE only where a tolerance exists

# Group-wise checks: numeric path ONLY if tolerance is defined
group_matches <- dt[
  ,
  as.list(mapply(
    function(v, nm) {
      t <- tol[[nm]]

      # If both values are NA -> match
      if (all(is.na(v))) {
        return(TRUE)
      }

      # Numeric path if tolerance is defined
      if (tol_defined[[nm]]) {
        nv <- suppressWarnings(as.numeric(v))
        if (anyNA(nv)) {
          # If any non-NA mismatch exists, return FALSE
          return(FALSE)
        } else {
          r <- range(nv)
          return((r[2] - r[1]) <= t)
        }
      } else {
        # Exact raw string match
        # If some values are NA (but not all), it's a mismatch
        if (anyNA(v)) {
          return(FALSE)
        }
        # Check all raw values are identical
        return(uniqueN(v) <= 1)
      }
    },
    .SD, names(.SD),
    SIMPLIFY = FALSE
  )),
  by = key_cols,
  .SDcols = cols
]


# Long form of match flags (used by BOTH outputs)
gm_long <- melt(
  as.data.table(group_matches),
  id.vars = key_cols,
  variable.name = "column",
  value.name = "is_match"
)

# Count of NOT matching values
count_not_matching <- gm_long[is_match == FALSE,
  .(Count = .N),
  by = .(Column = column)
][order(-Count)]
```

::: {.panel-tabset}

## Count of Unmatched Values
```{r unmatched_values}
DT::datatable(
  count_not_matching,
  options = list(
    scrollY = "300px",
    scrollX = TRUE,
    paging = TRUE,
    pageLength = 100,
    searching = TRUE
  ),
  rownames = FALSE
)
```

## Card Level Changes

```{r card_level_changes}
# Unmatched values by year
dt_long <- melt(
  dt,
  id.vars = c(key_cols, "year"),
  measure.vars = cols,
  variable.name = "column",
  value.name = "value"
)

# Keys that failed tolerance
unmatched_idx <- gm_long[is_match == FALSE, .(meta_pin, meta_card_num, column)]

# Keep values only for failed triples
unmatched_values_long <- merge(
  dt_long, unmatched_idx,
  by = c("meta_pin", "meta_card_num", "column"),
  all = FALSE
)

# Wide with year-suffixed columns
unmatched_wide <- dcast(
  unmatched_values_long,
  meta_pin + meta_card_num ~ column + year,
  value.var = "value",
  sep = "_"
)

# Sample for readability
if (nrow(unmatched_wide) > 10000) {
  unmatched_wide <- unmatched_wide[sample(.N, 10000)]
}

DT::datatable(
  unmatched_wide,
  extensions = "Scroller",
  options = list(
    deferRender = TRUE,
    scrollY = 400,
    scroller = TRUE,
    scrollX = TRUE,
    paging = TRUE,
    pageLength = 100,
    lengthMenu = c(10, 25, 50, 100),
    searching = TRUE
  ),
  rownames = FALSE
)
```
:::
