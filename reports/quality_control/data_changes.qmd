

```{r}
#| cache: true
#| cache-extra: !expr rlang::hash(params)
#| cache-file-1: !expr rlang::hash_file("_baseline_query_data.R")
#| cache-file-2: !expr rlang::hash_file("_utils.R")
```


```{r _data_changes_setup_script}
source("_baseline_query_data.R")
```

# Changed Values by Year

```{r}
# tolerance list:

# Many of our features shouild be exact matches but are not. For example,
# our distance to features have some minor variation due to geocoding variance.
# Because of this, all distance features have a buffer of 5 feet.
# There are also features which should not match, but we want to make sure that
# they stay relatively stable. For example, the percentage of college educated
# individuals should not change by more than 5% year over year.
card_data <- rbind(comp_chars, baseline_chars)
dt <- as.data.table(card_data)[order(meta_pin, meta_card_num)]
setnames(dt, "meta_year", "year")

key_cols <- c("meta_pin", "meta_card_num")
cols <- setdiff(names(dt), key_cols)

# Create tolerance list
base_tol <- c(
  acs5_median_age_total = 5,
  acs5_median_household_renter_occupied_gross_rent = 400,
  acs5_median_household_total_occupied_year_built = 5,
  acs5_median_income_household_past_year = 5000,
  acs5_median_income_per_capita_past_year = 5000,
  ccao_n_years_exe_homeowner = 1,
  loc_latitude = 0.0001,
  loc_longitude = 0.0001,
  other_tax_bill_rate = 0.5,
  prox_airport_dnl_total = 1,
  prox_num_foreclosure_per_1000_pin_past_5_years = 5,
  time_sale_day = 31,
  time_sale_day_of_week = 7,
  time_sale_year = 1,
  year = 1
)

make_tol <- function(cols) {
  tibble(col = cols) %>%
    mutate(val = case_when(
      col %in% names(base_tol) ~ base_tol[match(col, names(base_tol))],
      str_detect(col, "dist_ft$") ~ 5,
      str_detect(col, "^acs5_percent_") ~ 0.05,
      TRUE ~ NA_real_
    )) %>%
    {
      setNames(.$val, .$col)
    }
}

tol <- make_tol(cols)

tol_defined <- !is.na(tol) # TRUE only where a tolerance exists

# Group-wise checks: numeric path ONLY if tolerance is defined ---
group_matches <- dt[
  ,
  as.list(mapply(
    function(v, nm) {
      t <- tol[[nm]]

      # if both values are NA -> match
      if (all(is.na(v))) {
        return(TRUE)
      }

      if (tol_defined[[nm]]) {
        # try numeric path (only if coercion yields no NAs)
        nv <- suppressWarnings(as.numeric(v))
        if (anyNA(nv)) {
          # Since we qualify if both is NA we return a match,
          # either NA will return a FALSE match here
          return(FALSE)
        } else {
          r <- range(nv)
          return((r[2] - r[1]) <= t)
        }
      } else {
        # exact match after normalization
        sv <- tolower(trimws(as.character(v)))
        # "both NA" handled above; here NA present in only one side -> non-match
        if (anyNA(sv)) {
          return(FALSE)
        }
        return(uniqueN(sv) <= 1)
      }
    },
    .SD, names(.SD),
    SIMPLIFY = FALSE
  )),
  by = key_cols,
  .SDcols = cols
]

# Long form of match flags (used by BOTH outputs)
gm_long <- melt(
  as.data.table(group_matches),
  id.vars = key_cols,
  variable.name = "column",
  value.name = "is_match"
)

# Count of NOT matching values
count_not_matching <- gm_long[is_match == FALSE,
  .(Count = .N),
  by = .(Column = column)
][order(-Count)]
```

::: {.panel-tabset}

## Count of Unmatched Values
```{r}
DT::datatable(
  count_not_matching,
  options = list(
    scrollY = "300px",
    scrollX = TRUE,
    paging = TRUE,
    pageLength = 100,
    searching = TRUE
  ),
  rownames = FALSE
)

# Unmatched values by year
dt_long <- melt(
  dt,
  id.vars = c(key_cols, "year"),
  measure.vars = cols,
  variable.name = "column",
  value.name = "value"
)

# Keys that failed tolerance
unmatched_idx <- gm_long[is_match == FALSE, .(meta_pin, meta_card_num, column)]

# Keep values only for failed triples
unmatched_values_long <- merge(
  dt_long, unmatched_idx,
  by = c("meta_pin", "meta_card_num", "column"),
  all = FALSE
)

# Wide with year-suffixed columns
unmatched_wide <- dcast(
  unmatched_values_long,
  meta_pin + meta_card_num ~ column + year,
  value.var = "value",
  sep = "_"
)

# Sample for readability
if (nrow(unmatched_wide) > 10000) {
  unmatched_wide <- unmatched_wide[sample(.N, 10000)]
}
```
## Card Level Changes

```{r}
DT::datatable(
  unmatched_wide,
  extensions = "Scroller",
  options = list(
    deferRender = TRUE,
    scrollY = 400,
    scroller = TRUE,
    scrollX = TRUE,
    paging = TRUE,
    pageLength = 100,
    lengthMenu = c(10, 25, 50, 100),
    searching = TRUE
  ),
  rownames = FALSE
)
```
:::
